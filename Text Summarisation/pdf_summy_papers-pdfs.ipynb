{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93e23ff3",
   "metadata": {},
   "source": [
    "# TextRank algorithm\n",
    "\n",
    "1.TextRank is an extractive summarization technique.\n",
    "\n",
    "2.It is based on the concept that words which occur more frequently are significant.\n",
    "\n",
    "3.Hence , the sentences containing highly frequent words are important .\n",
    "\n",
    "4.Based on this , the algorithm assigns scores to each sentence in the text . \n",
    "\n",
    "5.The top-ranked sentences make it to the summary.\n",
    "\n",
    "pip install PyMuPDF\n",
    "pip install frontend\n",
    "pip install pdfplumber\n",
    "pip install PyMuPDF\n",
    "pip install fitz\n",
    "pip install rouge==1.0.0\n",
    "pip install streamlit==0.80.0\n",
    "pip install gensim==4.0.1\n",
    "pip install altair==4.1.0\n",
    "pip install pandas==1.2.3\n",
    "pip install sumy==0.8.1\n",
    "pip install gensim==3.8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d197d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebf2089b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pip install bert-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d257098d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import tensorflow as tf \n",
    "##Print many staement at same time using the below command\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b2d29e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install PyMuPDF\n",
    "import fitz\n",
    "import glob\n",
    "import pdfplumber\n",
    "import re\n",
    "\n",
    "#pip install sacrebleu\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import gensim\n",
    "from gensim.summarization import summarize\n",
    "from rouge import Rouge\n",
    "\n",
    "\n",
    "import bert_score\n",
    "from bert_score import score\n",
    "import matplotlib.pyplot as plt\n",
    "from bert_score import BERTScorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1344ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "F1_textrank=''\n",
    "F1_luhan=''\n",
    "F1_kl=''\n",
    "F1_lex=''\n",
    "F1_lsa=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "029c1aba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++++++++++++++++++++++++++++++++ ./data/1811.12015.pdf\n",
      "number of pages: 19\n",
      "+++++++++++++++++++++++++++++++++++++++++++ ./data/2006.12720.pdf\n",
      "number of pages: 16\n",
      "+++++++++++++++++++++++++++++++++++++++++++ ./data/2106.07909 (1).pdf\n",
      "number of pages: 22\n"
     ]
    }
   ],
   "source": [
    "pdf_dir = \"./data\"\n",
    "\n",
    "pdf_files = glob.glob(\"%s/*.pdf\" % pdf_dir)\n",
    "all_abstracts = \"\"\n",
    "for filename in pdf_files:\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++\",filename)\n",
    "    doc = fitz.open(filename)\n",
    "    print (\"number of pages: %i\" % doc.pageCount)\n",
    "\n",
    "    page1 = doc.loadPage(0)\n",
    "    page1text = page1.getText(\"text\")\n",
    "\n",
    "    page2 = doc.loadPage(1)\n",
    "    page2text = page2.getText(\"text\")\n",
    "\n",
    "    try:\n",
    "        try:\n",
    "            Abstract = page1text.split(\"Introduction\",1)[1]\n",
    "            partitioned_string = page2text.split('Data')[0]\n",
    "        except:\n",
    "            Abstract = page1text.split(\"Introduction\",1)[1]\n",
    "            partitioned_string = Abstract.split('Data')[0]\n",
    "    except Exception as IndexError:\n",
    "        try:\n",
    "            Abstract = page2text.split(\"Introduction\",1)[1]\n",
    "            partitioned_string = Abstract.split('Data')[0]\n",
    "        except:\n",
    "            Abstract = page2text.split(\"Introduction\",1)[1]\n",
    "            partitioned_string = Abstract.split('Data')[0]\n",
    "    partitioned_string = re.sub('\\S+@\\S+',\"\",partitioned_string)\n",
    "    partitioned_string = re.sub(r'[0-9]',\"\",partitioned_string)\n",
    "    #partitioned_string = \" \".join(re.findall(r\"[a-zA-Z0-9]+\",partitioned_string ))\n",
    "    all_abstracts += partitioned_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5e4ba28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = BeautifulSoup(text, \"lxml\").get_text()\n",
    "    # Removing the @\n",
    "    text = re.sub(r\"@[A-Za-z0-9]+\", ' ', text)\n",
    "    # Removing the URL links\n",
    "    text = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', text)\n",
    "    # Keeping only letters\n",
    "    text = re.sub(r\"[^a-zA-Z.!?']\", ' ', text)\n",
    "    # Removing additional whitespaces\n",
    "    text = re.sub(r\" +\", ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00e9b142",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_text = all_abstracts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ade0628d",
   "metadata": {},
   "outputs": [],
   "source": [
    "textRank_summary = summarize(original_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5f3b1d",
   "metadata": {},
   "source": [
    "## Matrices Evalution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9971b4a6",
   "metadata": {},
   "source": [
    "### Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "403e6110",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Rouge()\n",
    "score_text=r.get_scores(textRank_summary, original_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5ab44cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('textRank__org.txt', 'w')\n",
    "file.write(original_text)\n",
    "file.close()\n",
    "\n",
    "file = open('textRank_hyps.txt', 'w')\n",
    "file.write(textRank_summary)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bfaf974",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"textRank_hyps.txt\") as f:\n",
    "    cands = [line.strip() for line in f]\n",
    "\n",
    "with open(\"textRank__org.txt\") as f:\n",
    "    refs = [[line.strip() for line in f]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41290d5",
   "metadata": {},
   "source": [
    "### Blue Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59fe2dc7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score -> 5.037094777266818e-156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/NLG/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "\n",
      "/opt/anaconda3/envs/NLG/lib/python3.8/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "blue_score_textrank=sentence_bleu(refs, cands)\n",
    "print('BLEU score -> {}'.format(sentence_bleu(refs, cands)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d30c223",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual 1-gram: 0.039184\n",
      "Individual 2-gram: 0.006369\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n"
     ]
    }
   ],
   "source": [
    "print('Individual 1-gram: %f' % sentence_bleu(refs, cands, weights=(1, 0, 0, 0)))\n",
    "print('Individual 2-gram: %f' % sentence_bleu(refs, cands, weights=(0, 1, 0, 0)))\n",
    "print('Individual 3-gram: %f' % sentence_bleu(refs, cands, weights=(0, 0, 1, 0)))\n",
    "print('Individual 4-gram: %f' % sentence_bleu(refs, cands, weights=(0, 0, 0, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02f9564",
   "metadata": {},
   "source": [
    "### Bert Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28a8ad21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if len(cands)==1:\n",
    "    P, R, F1 = score(cands, refs, lang='en', rescale_with_baseline=True)\n",
    "    F1_textrank=F1\n",
    "    plt.hist(F1, bins=20)\n",
    "    plt.xlabel(\"score\")\n",
    "    plt.ylabel(\"counts\")\n",
    "    plt.show()\n",
    "\n",
    "if len(cands)>1:\n",
    "    scorer = BERTScorer(lang=\"en\", rescale_with_baseline=True)\n",
    "    P, R, F1 = scorer.score(cands, refs)\n",
    "    F1_textrank=F1\n",
    "    plt.hist(F1, bins=20)\n",
    "    plt.xlabel(\"score\")\n",
    "    plt.ylabel(\"counts\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a00d9e",
   "metadata": {},
   "source": [
    "# Text Summarization with Sumy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f18f2c6",
   "metadata": {},
   "source": [
    "# LexRank\n",
    "1.A sentence which is similar to many other sentences of the text has a high probability of being important. \n",
    "\n",
    "2.The approach of LexRank is that a particular sentence is recommended by other similar sentences and hence is ranked higher.\n",
    "\n",
    "3.Higher the rank, higher is the priority of being included in the summarized text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70110ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the parser and tokenizer\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fc47c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the parser\n",
    "my_parser = PlaintextParser.from_string(original_text,Tokenizer('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6614cc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the LexRank summarizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "944d46af",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Creating a summary of 3 sentences.\n",
    "lex_rank_summarizer = LexRankSummarizer()\n",
    "lexrank_summary = lex_rank_summarizer(my_parser.document,sentences_count=10)\n",
    "\n",
    "lex_summary = \"\"\n",
    "# Printing the summary\n",
    "for sentence in lexrank_summary:\n",
    "    lex_summary +=str(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ba0f8f",
   "metadata": {},
   "source": [
    "### Matrices Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4975f88b",
   "metadata": {},
   "source": [
    "### Rouge Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ab7273d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "r = Rouge()\n",
    "score_lexRank=r.get_scores(lex_summary, original_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f452a570",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('lexRank_hyps.txt', 'w')\n",
    "file.write(lex_summary)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8cad0a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"lexRank_hyps.txt\") as f:\n",
    "    cands_lex = [line.strip() for line in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d282df3",
   "metadata": {},
   "source": [
    "### Blue Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3659f9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score -> 0\n"
     ]
    }
   ],
   "source": [
    "blue_score_lex=sentence_bleu(refs, cands_lex)\n",
    "print('BLEU score -> {}'.format(sentence_bleu(refs, cands_lex)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cab2d18",
   "metadata": {},
   "source": [
    "### Bert Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2aa03650",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if len(cands_lex)==1:\n",
    "    P, R, F1 = score(cands_lex, refs, lang='en', rescale_with_baseline=True)\n",
    "    F1_lex=F1\n",
    "    plt.hist(F1, bins=20)\n",
    "    plt.xlabel(\"score\")\n",
    "    plt.ylabel(\"counts\")\n",
    "    plt.show()\n",
    "if len(cands_lex)>1:\n",
    "    scorer = BERTScorer(lang=\"en\", rescale_with_baseline=True)\n",
    "    P, R, F1 = scorer.score(cands_lex, refs)\n",
    "    F1_lex=F1\n",
    "    plt.hist(F1, bins=20)\n",
    "    plt.xlabel(\"score\")\n",
    "    plt.ylabel(\"counts\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55e2b7d",
   "metadata": {},
   "source": [
    "# LSA (Latent semantic analysis)\n",
    "Latent Semantic Analysis is a unsupervised learning algorithm that can be used for extractive text summarization.\n",
    "\n",
    "It extracts semantically significant sentences by applying singular value decomposition(SVD) to the matrix of term-document frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53ba9547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the summarizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c924cd91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# creating the summarizer\n",
    "lsa_summarizer=LsaSummarizer()\n",
    "lsa_summary= lsa_summarizer(my_parser.document,10)\n",
    "lsa_summary_text = \"\"\n",
    "# Printing the summary\n",
    "for sentence in lsa_summary:\n",
    "    lsa_summary_text +=str(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9471f5",
   "metadata": {},
   "source": [
    "## Matrices Evalution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7eadf297",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roug Score:\n",
      "BLEU score -> 0\n",
      "Bert Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Roug Score:\")\n",
    "r = Rouge()\n",
    "score_lsa=r.get_scores(lsa_summary_text, original_text)\n",
    "\n",
    "file = open('lsaRank__org.txt', 'w')\n",
    "file.write(original_text)\n",
    "file.close()\n",
    "\n",
    "file = open('lsaRank_hyps.txt', 'w')\n",
    "file.write(lsa_summary_text)\n",
    "file.close()\n",
    "\n",
    "\n",
    "with open(\"lsaRank_hyps.txt\") as f:\n",
    "    cands_lsa = [line.strip() for line in f]\n",
    "\n",
    "with open(\"lsaRank__org.txt\") as f:\n",
    "    refs_lsa = [[line.strip() for line in f]]\n",
    "\n",
    "\n",
    "print('BLEU score -> {}'.format(sentence_bleu(refs_lsa, cands_lex)))\n",
    "blue_score_lsa=sentence_bleu(refs_lsa, cands_lex)\n",
    "\n",
    "print(\"Bert Score:\")\n",
    "if len(cands_lsa)==1:\n",
    "    P, R, F1 = score(cands_lsa, refs_lsa, lang='en', rescale_with_baseline=True)\n",
    "    F1_lsa=F1\n",
    "    plt.hist(F1, bins=20)\n",
    "    plt.xlabel(\"score\")\n",
    "    plt.ylabel(\"counts\")\n",
    "    plt.show()\n",
    "if len(cands_lsa)>1:\n",
    "    scorer = BERTScorer(lang=\"en\", rescale_with_baseline=True)\n",
    "    P, R, F1 = scorer.score(cands_lsa, refs_lsa)\n",
    "    F1_lsa=F1\n",
    "    plt.hist(F1, bins=20)\n",
    "    plt.xlabel(\"score\")\n",
    "    plt.ylabel(\"counts\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b98076",
   "metadata": {},
   "source": [
    "# Luhn\n",
    "\n",
    "Luhn Summarization algorithmâ€™s approach is based on TF-IDF (Term Frequency-Inverse Document Frequency). It is useful when very low frequent words as well as highly frequent words(stopwords) are both not significant.\n",
    "\n",
    "Based on this, sentence scoring is carried out and the high ranking sentences make it to the summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e337ed7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the summarizer\n",
    "from sumy.summarizers.luhn import LuhnSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dbac5548",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  Creating the summarizer\n",
    "luhn_summarizer = LuhnSummarizer()\n",
    "luhn_summary = luhn_summarizer(my_parser.document,sentences_count=10)\n",
    "\n",
    "summary_luhn = \"\"\n",
    "# Printing the summary\n",
    "for sentence in luhn_summary:\n",
    "    summary_luhn +=str(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "30815959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roug Score:\n"
     ]
    }
   ],
   "source": [
    "print(\"Roug Score:\")\n",
    "r = Rouge()\n",
    "score_luhan=r.get_scores(summary_luhn, original_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46eae880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score -> 0\n",
      "Bert Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "file = open('luhan__org.txt', 'w')\n",
    "file.write(original_text)\n",
    "file.close()\n",
    "\n",
    "file = open('luhan_hyps.txt', 'w')\n",
    "file.write(summary_luhn)\n",
    "file.close()\n",
    "\n",
    "\n",
    "with open(\"luhan_hyps.txt\") as f:\n",
    "    cands_luhan = [line.strip() for line in f]\n",
    "\n",
    "with open(\"luhan__org.txt\") as f:\n",
    "    refs_luhan = [[line.strip() for line in f]]\n",
    "\n",
    "\n",
    "print('BLEU score -> {}'.format(sentence_bleu(refs_luhan, cands_luhan)))\n",
    "blue_score_luhan=sentence_bleu(refs_luhan, cands_luhan)\n",
    "\n",
    "print(\"Bert Score:\")\n",
    "if len(cands_luhan)==1:\n",
    "    P, R, F1 = score(cands_luhan, refs_luhan, lang='en', rescale_with_baseline=True)\n",
    "    F1_luhan=F1\n",
    "    plt.hist(F1, bins=20)\n",
    "    plt.xlabel(\"score\")\n",
    "    plt.ylabel(\"counts\")\n",
    "    plt.show()\n",
    "if len(cands_luhan)>1:\n",
    "    scorer = BERTScorer(lang=\"en\", rescale_with_baseline=True)\n",
    "    P, R, F1 = scorer.score(cands_luhan, refs_luhan)\n",
    "    F1_luhan=F1\n",
    "    plt.hist(F1, bins=20)\n",
    "    plt.xlabel(\"score\")\n",
    "    plt.ylabel(\"counts\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28884abc",
   "metadata": {},
   "source": [
    "# KL-Sum\n",
    "\n",
    "Another extractive method is the KL-Sum algorithm.\n",
    "\n",
    "It selects sentences based on similarity of word distribution as the original text. \n",
    "\n",
    "It aims to lower the KL-divergence criteria (learn more). \n",
    "\n",
    "It uses greedy optimization approach and keeps adding sentences till the KL-divergence decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "24f3fdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the summarizer\n",
    "from sumy.summarizers.kl import KLSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6165b082",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Instantiating the  KLSummarizer\n",
    "kl_summarizer = KLSummarizer()\n",
    "kl_summary = kl_summarizer(my_parser.document,sentences_count = 10)\n",
    "\n",
    "summary_kl_sum = \"\"\n",
    "# Printing the summary\n",
    "for sentence in kl_summary:\n",
    "    summary_kl_sum +=str(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a305b05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roug Score:\n",
      "BLEU score -> 0\n",
      "Bert Score:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Roug Score:\")\n",
    "r = Rouge()\n",
    "score_klsum=r.get_scores(summary_kl_sum, original_text)\n",
    "\n",
    "file = open('klsum__org.txt', 'w')\n",
    "file.write(original_text)\n",
    "file.close()\n",
    "\n",
    "file = open('klsum_hyps.txt', 'w')\n",
    "file.write(summary_kl_sum)\n",
    "file.close()\n",
    "\n",
    "\n",
    "with open(\"klsum_hyps.txt\") as f:\n",
    "    cands_kl = [line.strip() for line in f]\n",
    "\n",
    "with open(\"klsum__org.txt\") as f:\n",
    "    refs_kl = [[line.strip() for line in f]]\n",
    "\n",
    "\n",
    "print('BLEU score -> {}'.format(sentence_bleu(refs_kl, cands_kl)))\n",
    "blue_score_klsum=sentence_bleu(refs_kl, cands_kl)\n",
    "\n",
    "print(\"Bert Score:\")\n",
    "\n",
    "if len(cands_kl)==1:\n",
    "    P, R, F1 = score(cands_kl, refs_kl, lang='en', rescale_with_baseline=True)\n",
    "    F1_kl=F1\n",
    "    plt.hist(F1, bins=20)\n",
    "    plt.xlabel(\"score\")\n",
    "    plt.ylabel(\"counts\")\n",
    "    plt.show()\n",
    "if len(cands_kl)>1:\n",
    "    scorer = BERTScorer(lang=\"en\", rescale_with_baseline=True)\n",
    "    P, R, F1 = scorer.score(cands_kl, refs_kl)\n",
    "    F1_kl=F1\n",
    "    plt.hist(F1, bins=20)\n",
    "    plt.xlabel(\"score\")\n",
    "    plt.ylabel(\"counts\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d6237a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "be752b30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ROUGE-1</th>\n",
       "      <th>f</th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Text Rank</th>\n",
       "      <td>0.413</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lex Rank</th>\n",
       "      <td>0.277</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSA</th>\n",
       "      <td>0.238</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Luhan</th>\n",
       "      <td>0.462</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KL Sum</th>\n",
       "      <td>0.212</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ROUGE-1        f      p      r\n",
       "All                           \n",
       "Text Rank  0.413  1.000  0.260\n",
       "Lex Rank   0.277  1.000  0.161\n",
       "LSA        0.238  1.000  0.135\n",
       "Luhan      0.462  1.000  0.301\n",
       "KL Sum     0.212  0.996  0.118"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wrap rouge score in dataframe\n",
    "df_textRank = pd.DataFrame(score_text[0]['rouge-1'], index=['Text Rank']).apply(lambda x: round(x,3))\n",
    "df_lexRank = pd.DataFrame(score_lexRank[0]['rouge-1'], index=['Lex Rank']).apply(lambda x: round(x,3))\n",
    "df_lsa = pd.DataFrame(score_lsa[0]['rouge-1'], index=['LSA']).apply(lambda x: round(x,3))\n",
    "df_luhan = pd.DataFrame(score_luhan[0]['rouge-1'], index=['Luhan']).apply(lambda x: round(x,3))\n",
    "df_klsum = pd.DataFrame(score_klsum[0]['rouge-1'], index=['KL Sum']).apply(lambda x: round(x,3))\n",
    "#concatenate and display\n",
    "df_all_rough1= pd.concat([df_textRank, df_lexRank, df_lsa,df_luhan,df_klsum]) \n",
    "df_all_rough1.columns.name = 'ROUGE-1'\n",
    "df_all_rough1.index.name = 'All'\n",
    "df_all_rough1[['f', 'p', 'r']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ac42db84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ROUGE-2</th>\n",
       "      <th>f</th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Text Rank</th>\n",
       "      <td>0.392</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lex Rank</th>\n",
       "      <td>0.269</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSA</th>\n",
       "      <td>0.230</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Luhan</th>\n",
       "      <td>0.458</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KL Sum</th>\n",
       "      <td>0.203</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ROUGE-2        f      p      r\n",
       "All                           \n",
       "Text Rank  0.392  0.951  0.247\n",
       "Lex Rank   0.269  0.973  0.156\n",
       "LSA        0.230  0.972  0.131\n",
       "Luhan      0.458  0.991  0.298\n",
       "KL Sum     0.203  0.959  0.114"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wrap rouge score in dataframe\n",
    "df_textRank = pd.DataFrame(score_text[0]['rouge-2'], index=['Text Rank']).apply(lambda x: round(x,3))\n",
    "df_lexRank = pd.DataFrame(score_lexRank[0]['rouge-2'], index=['Lex Rank']).apply(lambda x: round(x,3))\n",
    "df_lsa = pd.DataFrame(score_lsa[0]['rouge-2'], index=['LSA']).apply(lambda x: round(x,3))\n",
    "df_luhan = pd.DataFrame(score_luhan[0]['rouge-2'], index=['Luhan']).apply(lambda x: round(x,3))\n",
    "df_klsum = pd.DataFrame(score_klsum[0]['rouge-2'], index=['KL Sum']).apply(lambda x: round(x,3))\n",
    "#concatenate and display\n",
    "df_all_rough2= pd.concat([df_textRank, df_lexRank, df_lsa,df_luhan,df_klsum]) \n",
    "df_all_rough2.columns.name = 'ROUGE-2'\n",
    "df_all_rough2.index.name = 'All'\n",
    "df_all_rough2[['f', 'p', 'r']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dba3f662",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ROUGE-L</th>\n",
       "      <th>f</th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Text Rank</th>\n",
       "      <td>0.479</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lex Rank</th>\n",
       "      <td>0.372</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSA</th>\n",
       "      <td>0.348</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Luhan</th>\n",
       "      <td>0.567</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KL Sum</th>\n",
       "      <td>0.332</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ROUGE-L        f      p      r\n",
       "All                           \n",
       "Text Rank  0.479  1.000  0.315\n",
       "Lex Rank   0.372  1.000  0.229\n",
       "LSA        0.348  1.000  0.211\n",
       "Luhan      0.567  1.000  0.395\n",
       "KL Sum     0.332  0.994  0.199"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wrap rouge score in dataframe\n",
    "df_textRank = pd.DataFrame(score_text[0]['rouge-l'], index=['Text Rank']).apply(lambda x: round(x,3))\n",
    "df_lexRank = pd.DataFrame(score_lexRank[0]['rouge-l'], index=['Lex Rank']).apply(lambda x: round(x,3))\n",
    "df_lsa = pd.DataFrame(score_lsa[0]['rouge-l'], index=['LSA']).apply(lambda x: round(x,3))\n",
    "df_luhan = pd.DataFrame(score_luhan[0]['rouge-l'], index=['Luhan']).apply(lambda x: round(x,3))\n",
    "df_klsum = pd.DataFrame(score_klsum[0]['rouge-l'], index=['KL Sum']).apply(lambda x: round(x,3))\n",
    "#concatenate and display\n",
    "df_all_roughL= pd.concat([df_textRank, df_lexRank, df_lsa,df_luhan,df_klsum]) \n",
    "df_all_roughL.columns.name = 'ROUGE-L'\n",
    "df_all_roughL.index.name = 'All'\n",
    "df_all_roughL[['f', 'p', 'r']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1332179e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ROUGE-1</th>\n",
       "      <th>f</th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Text Rank</th>\n",
       "      <td>0.413</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lex Rank</th>\n",
       "      <td>0.277</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSA</th>\n",
       "      <td>0.238</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Luhan</th>\n",
       "      <td>0.462</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KL Sum</th>\n",
       "      <td>0.212</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ROUGE-1        f      p      r\n",
       "All                           \n",
       "Text Rank  0.413  1.000  0.260\n",
       "Lex Rank   0.277  1.000  0.161\n",
       "LSA        0.238  1.000  0.135\n",
       "Luhan      0.462  1.000  0.301\n",
       "KL Sum     0.212  0.996  0.118"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ROUGE-2</th>\n",
       "      <th>f</th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Text Rank</th>\n",
       "      <td>0.392</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lex Rank</th>\n",
       "      <td>0.269</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSA</th>\n",
       "      <td>0.230</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Luhan</th>\n",
       "      <td>0.458</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KL Sum</th>\n",
       "      <td>0.203</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ROUGE-2        f      p      r\n",
       "All                           \n",
       "Text Rank  0.392  0.951  0.247\n",
       "Lex Rank   0.269  0.973  0.156\n",
       "LSA        0.230  0.972  0.131\n",
       "Luhan      0.458  0.991  0.298\n",
       "KL Sum     0.203  0.959  0.114"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ROUGE-L</th>\n",
       "      <th>f</th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Text Rank</th>\n",
       "      <td>0.479</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lex Rank</th>\n",
       "      <td>0.372</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSA</th>\n",
       "      <td>0.348</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Luhan</th>\n",
       "      <td>0.567</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KL Sum</th>\n",
       "      <td>0.332</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ROUGE-L        f      p      r\n",
       "All                           \n",
       "Text Rank  0.479  1.000  0.315\n",
       "Lex Rank   0.372  1.000  0.229\n",
       "LSA        0.348  1.000  0.211\n",
       "Luhan      0.567  1.000  0.395\n",
       "KL Sum     0.332  0.994  0.199"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_rough1\n",
    "df_all_rough2\n",
    "df_all_roughL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c18a6a91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blue Score: \n",
      "Text Rank: 5.037094777266818e-156\n",
      "Lex Rank: 0\n",
      "LSA: 0\n",
      "Luhn: 0\n",
      "KL Sum: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Blue Score: \")\n",
    "\n",
    "print('Text Rank: '+str(blue_score_textrank))\n",
    "print('Lex Rank: '+str(blue_score_lex))\n",
    "print('LSA: '+str(blue_score_lsa))\n",
    "print('Luhn: '+str(blue_score_luhan))\n",
    "print('KL Sum: '+str(blue_score_klsum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ddff2244",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "textRank=tf.constant(F1_textrank).numpy()\n",
    "lex=tf.constant(F1_lex).numpy()\n",
    "lsa=tf.constant(F1_lsa).numpy()\n",
    "luhn=tf.constant(F1_luhan).numpy()\n",
    "kl=tf.constant(F1_kl).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2034e69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Score:\n",
      "Text Rank: [1.]\n",
      "Lex Rank: [0.16667655]\n",
      "LSA: [0.16026878]\n",
      "Luhn: [0.08607864]\n",
      "KL Sum: [0.20216085]\n"
     ]
    }
   ],
   "source": [
    "print(\"BERT Score:\")\n",
    "print('Text Rank: '+str(textRank))\n",
    "print('Lex Rank: '+str(lex))\n",
    "print('LSA: '+str(lsa))\n",
    "print('Luhn: '+str(luhn))\n",
    "print('KL Sum: '+str(kl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e758c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cbb384",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
